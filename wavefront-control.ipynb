{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70e46aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Skipping torch.nn as it is not installed.\n",
      "WARNING: Skipping torch.optim as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.0)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sujatha\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.5 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchaudio"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully installed torch-2.7.0 torchaudio-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch -y\n",
    "!pip uninstall torch.nn -y\n",
    "!pip uninstall torch.optim -y\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baaf1d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ----------------\n",
      "anyio                     4.6.0\n",
      "appdirs                   1.4.4\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "blinker                   1.9.0\n",
      "certifi                   2024.8.30\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "cloudpickle               3.1.1\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.0\n",
      "cycler                    0.12.1\n",
      "deap                      1.4.3\n",
      "debugpy                   1.8.5\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.1.0\n",
      "Farama-Notifications      0.0.4\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.17.0\n",
      "Flask                     3.1.0\n",
      "fonttools                 4.54.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2025.2.0\n",
      "gymnasium                 0.28.1\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.6\n",
      "httpx                     0.27.2\n",
      "huggingface-hub           0.29.1\n",
      "idna                      3.10\n",
      "imageio                   2.36.1\n",
      "importlib_metadata        8.6.1\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.27.0\n",
      "isoduration               20.11.0\n",
      "itsdangerous              2.2.0\n",
      "jax-jumpy                 1.0.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.5\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "kiwisolver                1.4.7\n",
      "lazy_loader               0.4\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.2\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.0.2\n",
      "mpmath                    1.3.0\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "notebook                  7.2.2\n",
      "notebook-as-pdf           0.5.0\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.1.2\n",
      "opencv-python             4.11.0.86\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pdfkit                    1.0.0\n",
      "pillow                    10.4.0\n",
      "pip                       24.2\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.0\n",
      "prompt_toolkit            3.0.47\n",
      "psutil                    6.0.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "pyee                      11.1.1\n",
      "Pygments                  2.18.0\n",
      "pyparsing                 3.1.4\n",
      "PyPDF2                    3.0.1\n",
      "pyppeteer                 2.0.0\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytorch-ignite            0.5.2\n",
      "pytz                      2024.2\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.13\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "referencing               0.35.1\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.20.0\n",
      "scikit-image              0.25.0\n",
      "scikit-learn              1.5.2\n",
      "scipy                     1.14.1\n",
      "sdtfile                   2025.3.25\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.1.0\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soundfile                 0.12.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.14.0\n",
      "terminado                 0.18.1\n",
      "thop                      0.1.1-2209072238\n",
      "threadpoolctl             3.5.0\n",
      "tifffile                  2025.1.10\n",
      "tinycss2                  1.3.0\n",
      "torch                     2.7.0\n",
      "torch-pruning             1.5.2\n",
      "torchaudio                2.7.0\n",
      "torchvision               0.22.0\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "types-python-dateutil     2.9.0.20240906\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2024.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   1.26.20\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.8.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "websockets                10.4\n",
      "Werkzeug                  3.1.3\n",
      "wfdb                      4.1.2\n",
      "zipp                      3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67973a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA available:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA device count:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3787d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.1.1-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\SUJATHA\\Desktop\\UC Davis\\Spring 2025\\ReinforcementLearning\\Project\\Tramission-Matrix\\rl-env\\Scripts\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting jinja2\n",
      "  Obtaining dependency information for jinja2 from https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Discarding https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl#sha256=bc5dd2abb727a5319567b7a813e6a2e7318c39f4f487cfe6c89c6f9c7d25197d (from https://download.pytorch.org/whl/cpu/jinja2/): Requested jinja2 from https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl#sha256=bc5dd2abb727a5319567b7a813e6a2e7318c39f4f487cfe6c89c6f9c7d25197d (from torch) has inconsistent Name: expected 'jinja2', but metadata has 'Jinja2'\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 133.2/133.2 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Obtaining dependency information for networkx from https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting fsspec\n",
      "  Obtaining dependency information for fsspec from https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filelock\n",
      "  Obtaining dependency information for filelock from https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl.metadata (59 kB)\n",
      "     ---------------------------------------- 0.0/59.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 59.7/59.7 kB ? eta 0:00:00\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Obtaining dependency information for pillow!=8.3.*,>=5.3.0 from https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     -------------------------------------  532.5/536.2 kB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 536.2/536.2 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl (215.2 MB)\n",
      "   ---------------------------------------- 0.0/215.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/215.2 MB 24.9 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 1.8/215.2 MB 18.8 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 2.7/215.2 MB 18.9 MB/s eta 0:00:12\n",
      "    --------------------------------------- 3.5/215.2 MB 18.7 MB/s eta 0:00:12\n",
      "    --------------------------------------- 4.5/215.2 MB 19.2 MB/s eta 0:00:11\n",
      "    --------------------------------------- 4.6/215.2 MB 16.4 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.9/215.2 MB 18.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 6.7/215.2 MB 17.7 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 7.6/215.2 MB 18.0 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 8.8/215.2 MB 18.8 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 9.8/215.2 MB 19.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 10.7/215.2 MB 18.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.1/215.2 MB 18.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 12.6/215.2 MB 19.3 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 13.4/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 14.9/215.2 MB 22.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 14.9/215.2 MB 21.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 16.2/215.2 MB 19.9 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 17.4/215.2 MB 21.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 18.6/215.2 MB 21.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 19.4/215.2 MB 21.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 20.3/215.2 MB 19.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 21.1/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 22.1/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 23.2/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 24.2/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 25.4/215.2 MB 22.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 26.4/215.2 MB 21.8 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 26.9/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 28.1/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 29.1/215.2 MB 20.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 30.0/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 31.0/215.2 MB 21.8 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 31.9/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 32.8/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 34.0/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 34.7/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 36.1/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 37.2/215.2 MB 22.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 38.3/215.2 MB 22.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 39.2/215.2 MB 21.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 40.3/215.2 MB 22.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 41.5/215.2 MB 23.4 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 42.0/215.2 MB 21.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 42.7/215.2 MB 22.6 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 43.9/215.2 MB 21.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 44.7/215.2 MB 21.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 45.1/215.2 MB 21.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 45.3/215.2 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 46.0/215.2 MB 18.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 47.1/215.2 MB 18.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 48.3/215.2 MB 18.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 49.5/215.2 MB 18.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 50.5/215.2 MB 18.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 51.6/215.2 MB 18.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 52.5/215.2 MB 18.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 53.4/215.2 MB 19.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 54.1/215.2 MB 18.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 54.7/215.2 MB 17.7 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.7/215.2 MB 19.9 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 56.5/215.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 57.4/215.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 58.4/215.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 59.4/215.2 MB 19.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 60.2/215.2 MB 19.9 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 61.1/215.2 MB 19.3 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 62.6/215.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 63.3/215.2 MB 19.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 64.3/215.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 65.2/215.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 66.4/215.2 MB 21.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 67.3/215.2 MB 21.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 68.4/215.2 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 69.2/215.2 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 70.3/215.2 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 71.2/215.2 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 72.1/215.2 MB 20.5 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 73.1/215.2 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 74.2/215.2 MB 21.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 75.4/215.2 MB 21.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 76.5/215.2 MB 21.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 77.4/215.2 MB 22.6 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 78.6/215.2 MB 21.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 80.0/215.2 MB 23.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 80.6/215.2 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 81.5/215.2 MB 22.5 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 82.6/215.2 MB 21.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 83.5/215.2 MB 21.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 84.7/215.2 MB 22.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 85.5/215.2 MB 21.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 86.2/215.2 MB 21.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 87.4/215.2 MB 21.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 88.3/215.2 MB 21.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 89.1/215.2 MB 21.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 90.0/215.2 MB 19.8 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 90.9/215.2 MB 21.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 91.9/215.2 MB 20.5 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 92.7/215.2 MB 20.5 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 93.4/215.2 MB 19.9 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 94.5/215.2 MB 19.9 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 95.5/215.2 MB 19.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 96.4/215.2 MB 19.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 97.0/215.2 MB 19.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 97.7/215.2 MB 19.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 98.4/215.2 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 99.1/215.2 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 99.9/215.2 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 100.8/215.2 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 101.4/215.2 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 101.7/215.2 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 102.9/215.2 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 104.0/215.2 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 104.9/215.2 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 105.8/215.2 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 106.9/215.2 MB 17.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 108.2/215.2 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 109.0/215.2 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 110.0/215.2 MB 19.9 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 110.8/215.2 MB 19.9 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 111.7/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 112.6/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 113.8/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 114.6/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 115.7/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 116.4/215.2 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 117.3/215.2 MB 19.8 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 118.3/215.2 MB 19.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 119.1/215.2 MB 20.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 120.4/215.2 MB 20.5 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 121.4/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 122.2/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 123.2/215.2 MB 20.5 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 124.2/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 125.1/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 126.1/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 127.0/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 127.9/215.2 MB 20.5 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 129.0/215.2 MB 21.1 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 130.2/215.2 MB 21.8 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 131.0/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 131.9/215.2 MB 20.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 132.9/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 133.7/215.2 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 134.6/215.2 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 135.6/215.2 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 136.9/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 138.0/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 139.1/215.2 MB 21.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 140.3/215.2 MB 21.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 140.4/215.2 MB 21.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 141.4/215.2 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 142.3/215.2 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 143.4/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 144.6/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 145.7/215.2 MB 21.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 146.6/215.2 MB 21.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 147.7/215.2 MB 21.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 148.1/215.2 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 149.4/215.2 MB 19.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 150.2/215.2 MB 19.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 151.1/215.2 MB 21.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 152.2/215.2 MB 21.1 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 153.2/215.2 MB 21.1 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 154.1/215.2 MB 21.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 155.1/215.2 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 156.4/215.2 MB 21.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 157.3/215.2 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 158.7/215.2 MB 23.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 159.9/215.2 MB 23.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 160.8/215.2 MB 23.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 161.5/215.2 MB 22.6 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 161.5/215.2 MB 21.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 162.0/215.2 MB 19.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 162.9/215.2 MB 19.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 164.0/215.2 MB 19.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 165.0/215.2 MB 19.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 166.1/215.2 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 167.0/215.2 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 168.2/215.2 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 169.2/215.2 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 170.4/215.2 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 171.2/215.2 MB 19.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 172.1/215.2 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 173.4/215.2 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 174.5/215.2 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 175.3/215.2 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 176.3/215.2 MB 21.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 177.6/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 178.7/215.2 MB 22.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 179.9/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 180.8/215.2 MB 22.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 181.7/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 182.9/215.2 MB 22.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 184.2/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 185.2/215.2 MB 24.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 186.3/215.2 MB 24.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 187.5/215.2 MB 24.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 188.6/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 189.3/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 190.4/215.2 MB 22.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 191.8/215.2 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 193.0/215.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 194.0/215.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 194.0/215.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 194.0/215.2 MB 20.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 194.0/215.2 MB 20.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 194.0/215.2 MB 20.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 194.1/215.2 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 195.1/215.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 196.1/215.2 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 197.2/215.2 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 198.4/215.2 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 198.9/215.2 MB 14.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 200.1/215.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 201.5/215.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 202.8/215.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 203.8/215.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 205.1/215.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 206.1/215.2 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 207.5/215.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 208.3/215.2 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 209.4/215.2 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  210.5/215.2 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  211.6/215.2 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  213.1/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  214.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.2/215.2 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 215.2/215.2 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.6/1.7 MB 34.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.5 MB 14.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.0/2.5 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.0/2.6 MB 31.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.0/2.6 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 23.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 18.1 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/6.2 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 3.0/6.2 MB 64.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.4/6.2 MB 57.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 49.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 177.6/177.6 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 31.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 21.4 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.9/12.9 MB 19.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 16.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 12.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.4/12.9 MB 13.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.9/12.9 MB 14.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.9/12.9 MB 14.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.9/12.9 MB 14.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.9/12.9 MB 14.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.9/12.9 MB 14.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.9 MB 15.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.6/12.9 MB 16.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.5/12.9 MB 16.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.6/12.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.7/12.9 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 15.6 MB/s eta 0:00:00\n",
      "Using cached https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl (215.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.3 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 sympy-1.13.3 torch-2.7.0+cpu torchaudio-2.7.0+cpu torchvision-0.22.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384af9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.58.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sujatha\\desktop\\uc davis\\spring 2025\\reinforcementlearning\\project\\tramission-matrix\\rl-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\SUJATHA\\\\Desktop\\\\UC Davis\\\\Spring 2025\\\\ReinforcementLearning\\\\Project\\\\Tramission-Matrix\\\\rl-env\\\\Lib\\\\site-packages\\\\cycler\\\\__init__.py'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixels: 4096\n",
      "Number of blocks: 128\n",
      "Pixels per block: 32\n",
      "All ON  Sum of pixels: 4096.0\n",
      "All OFF  Sum of pixels: 0.0\n",
      "Only block 0 ON  Sum of pixels: 32.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from torch.distributions import Categorical\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class WavefrontEnv:\n",
    "    def __init__(self, slm_dim1=64, slm_dim2=64, eng_size=1,\n",
    "                 num_pix_per_block=32, alpha=0.3, noise_sigma=0.05):\n",
    "        # geometry -----------------------------------------------------------\n",
    "        self.slm_dim1, self.slm_dim2 = slm_dim1, slm_dim2\n",
    "        self.n_pix   = slm_dim1 * slm_dim2            # 4096\n",
    "        self.eng_size = eng_size                      # up-sampling factor\n",
    "\n",
    "        # block grid ---------------------------------------------------------\n",
    "        self.blocks = self._make_blocks(num_pix_per_block)\n",
    "        self.num_blocks = len(self.blocks)            # 128 for 32-pix blocks\n",
    "\n",
    "        # RL bookkeeping -----------------------------------------------------\n",
    "        self.state_dim    = self.num_blocks + 1       # 128 bits + intensity\n",
    "        self.action_space = self.num_blocks\n",
    "        self.alpha  = alpha\n",
    "        self.sigma  = noise_sigma                     # measurement noise \n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    # ------------------------------------------------------------------ utils\n",
    "    def _make_blocks(self, p_per_block):\n",
    "        \"\"\"Return list of numpy arrays  each array holds pixel indices of one block.\"\"\"\n",
    "        idx = np.arange(self.n_pix)\n",
    "        return [idx[k : k + p_per_block]\n",
    "                for k in range(0, self.n_pix, p_per_block)]\n",
    "\n",
    "    def _blocks_to_pixels(self):\n",
    "        \"\"\"Convert block-level mask  2-D pixel mask (0/1).\"\"\"\n",
    "        pixel = np.zeros(self.n_pix, dtype=np.float32)\n",
    "        for bid, bit in enumerate(self.block_mask):\n",
    "            if bit:                                     # block is ON\n",
    "                pixel[self.blocks[bid]] = 1.0\n",
    "        return pixel.reshape(self.slm_dim1, self.slm_dim2)\n",
    "\n",
    "    # ------------------------------------------------------------- RL methods\n",
    "    def reset(self):\n",
    "        self.block_mask = np.ones(self.num_blocks, dtype=np.float32)   # all blocks ON\n",
    "        self.phi        = np.random.rand(self.slm_dim1, self.slm_dim2) # random phase\n",
    "        self.I_max  = 0.0\n",
    "        self.I_prev = self._intensity()\n",
    "        self.I0_mean = self.I_prev\n",
    "        return self._state()\n",
    "\n",
    "    def step(self, action: int):\n",
    "        # flip chosen block bit\n",
    "        self.block_mask[action] = 1.0 - self.block_mask[action]\n",
    "\n",
    "        I_t   = self._intensity()\n",
    "        delta = (I_t - self.I_prev) / self.I0_mean\n",
    "        bonus = max(0.0, I_t - self.I_max) / self.I0_mean\n",
    "        reward = delta + self.alpha * bonus - 1e-4      # small time penalty \n",
    "\n",
    "        # bookkeeping\n",
    "        self.I_prev = I_t\n",
    "        self.I_max  = max(self.I_max, I_t)\n",
    "\n",
    "        return self._state(), reward\n",
    "\n",
    "    # ---------------------------------------------------------------- optics\n",
    "    def _intensity(self):\n",
    "        mask2d = self._blocks_to_pixels()\n",
    "        field  = np.exp(1j * 2 * np.pi * self.phi) * mask2d\n",
    "        spec   = np.fft.fftshift(np.fft.fft2(field))\n",
    "        I      = np.abs(spec[self.slm_dim1 // 2, self.slm_dim2 // 2])**2 / spec.size\n",
    "        I     += self.sigma * np.random.randn()         # additive Gaussian noise\n",
    "        return float(I)\n",
    "\n",
    "    # ---------------------------------------------------------------- state\n",
    "    def _state(self):\n",
    "        norm_I = self.I_prev / self.I0_mean\n",
    "        return np.concatenate([self.block_mask, [norm_I]]).astype(np.float32)\n",
    "\n",
    "# Deep Q-Network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.out = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.out(x)\n",
    "\n",
    "# Experience Replay\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=10000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state):\n",
    "        self.buffer.append((state, action, reward, next_state))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state = map(np.array, zip(*batch))\n",
    "        return (\n",
    "            torch.FloatTensor(state),\n",
    "            torch.LongTensor(action),\n",
    "            torch.FloatTensor(reward),\n",
    "            torch.FloatTensor(next_state),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# Training loop setup\n",
    "def train_dqn(episodes=1000, max_steps=128, batch_size=64):\n",
    "    env = WavefrontEnv()\n",
    "    state_dim = env.num_pixels + 1\n",
    "    n_actions = env.num_blocks\n",
    "\n",
    "    policy_net = DQN(state_dim, n_actions)\n",
    "    target_net = DQN(state_dim, n_actions)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=1e-4)\n",
    "    buffer = ReplayBuffer()\n",
    "    gamma = 0.99\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.995\n",
    "    epsilon_min = 0.05\n",
    "    update_target_steps = 100\n",
    "    target_update_counter = 0\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        for step in range(max_steps):\n",
    "            if random.random() < epsilon:\n",
    "                action = random.randint(0, n_actions - 1)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "                    q_values = policy_net(state_tensor)\n",
    "                    action = q_values.argmax().item()\n",
    "\n",
    "            next_state, reward, _, _ = env.step(action)\n",
    "            buffer.push(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if len(buffer) >= batch_size:\n",
    "                s_batch, a_batch, r_batch, ns_batch = buffer.sample(batch_size)\n",
    "                q_vals = policy_net(s_batch).gather(1, a_batch.unsqueeze(1)).squeeze()\n",
    "                next_q_vals = target_net(ns_batch).max(1)[0]\n",
    "                target = r_batch + gamma * next_q_vals\n",
    "\n",
    "                loss = nn.MSELoss()(q_vals, target.detach())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                target_update_counter += 1\n",
    "                if target_update_counter % update_target_steps == 0:\n",
    "                    target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "        print(f\"Episode {ep + 1}, Total Reward: {total_reward:.4f}, Epsilon: {epsilon:.3f}\")\n",
    "\n",
    "# You can run train_dqn() locally to train the agent\n",
    "# train_dqn()\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# 2. Actor-Critic network                                                     #\n",
    "# --------------------------------------------------------------------------- #\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        # Common layers\n",
    "        self.fc_common = nn.Sequential(\n",
    "            nn.Linear(state_dim, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Actor network (policy)\n",
    "        self.actor_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_dim)\n",
    "        )\n",
    "        \n",
    "        # Critic network (value function)\n",
    "        self.critic_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_common(x)\n",
    "        \n",
    "        # Actor: Action probabilities\n",
    "        action_probs = torch.softmax(self.actor_head(x), dim=-1)\n",
    "        \n",
    "        # Critic: State value\n",
    "        state_value = self.critic_head(x)\n",
    "        \n",
    "        return action_probs, state_value\n",
    "    \n",
    "    def get_action(self, state, deterministic=False):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action_probs, _ = self.forward(state)\n",
    "        \n",
    "        if deterministic:\n",
    "            action = torch.argmax(action_probs, dim=-1).item()\n",
    "        else:\n",
    "            dist = Categorical(action_probs)\n",
    "            action = dist.sample().item()\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def evaluate(self, states, actions):\n",
    "        action_probs, state_values = self.forward(states)\n",
    "        dist = Categorical(action_probs)\n",
    "        \n",
    "        action_log_probs = dist.log_prob(actions)\n",
    "        dist_entropy = dist.entropy()\n",
    "        \n",
    "        return action_log_probs, state_values, dist_entropy\n",
    "\n",
    "# PPO Agent\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_dim, action_dim, lr=3e-4, gamma=0.99, \n",
    "                 clip_ratio=0.2, value_coef=0.5, entropy_coef=0.01, gae_lambda=0.95):\n",
    "        self.gamma = gamma\n",
    "        self.clip_ratio = clip_ratio\n",
    "        self.value_coef = value_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.gae_lambda = gae_lambda\n",
    "        \n",
    "        self.policy = ActorCritic(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        \n",
    "        self.old_policy = copy.deepcopy(self.policy)\n",
    "        self.old_policy.eval()  # Set to evaluation mode\n",
    "    \n",
    "    def update(self, states, actions, rewards, next_states, steps_per_epoch=128, epochs=10):\n",
    "        # Convert to tensors\n",
    "        states = torch.FloatTensor(np.array(states))\n",
    "        actions = torch.LongTensor(np.array(actions))\n",
    "        rewards = torch.FloatTensor(np.array(rewards))\n",
    "        next_states = torch.FloatTensor(np.array(next_states))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            old_action_log_probs, old_values, _ = self.old_policy.evaluate(states, actions)\n",
    "            next_values = self.old_policy.forward(next_states)[1].squeeze(-1)\n",
    "            values = torch.cat([old_values, next_values[-1].unsqueeze(0)], dim=0)\n",
    "\n",
    "        # Calculate advantages using GAE (Generalized Advantage Estimation)\n",
    "        advantages = torch.zeros_like(rewards)\n",
    "        returns = torch.zeros_like(rewards)\n",
    "        gae = 0\n",
    "\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            next_value = values[t + 1]\n",
    "            delta = rewards[t] + self.gamma * next_value - old_values[t]\n",
    "            gae = delta + self.gamma * self.gae_lambda * gae\n",
    "            advantages[t] = gae\n",
    "        \n",
    "        # Compute returns (used for value function loss)\n",
    "        returns = advantages + old_values.detach()\n",
    "        \n",
    "        # Normalize advantages\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "        # PPO update loop\n",
    "        for _ in range(epochs):\n",
    "            # Create random indices for minibatches\n",
    "            indices = np.random.permutation(len(states))\n",
    "            \n",
    "            # Iterate through mini-batches\n",
    "            for start in range(0, len(states), steps_per_epoch):\n",
    "                end = start + steps_per_epoch\n",
    "                if end > len(states):\n",
    "                    end = len(states)\n",
    "                    \n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                # Get batch data\n",
    "                batch_states = states[batch_indices]\n",
    "                batch_actions = actions[batch_indices]\n",
    "                batch_advantages = advantages[batch_indices]\n",
    "                batch_returns = returns[batch_indices]\n",
    "                batch_old_action_log_probs = old_action_log_probs[batch_indices]\n",
    "                \n",
    "                # Evaluate current policy\n",
    "                action_log_probs, values, entropy = self.policy.evaluate(batch_states, batch_actions)\n",
    "                \n",
    "                # Calculate ratios\n",
    "                ratios = torch.exp(action_log_probs - batch_old_action_log_probs)\n",
    "                \n",
    "                # Compute surrogate losses\n",
    "                surr1 = ratios * batch_advantages\n",
    "                surr2 = torch.clamp(ratios, 1.0 - self.clip_ratio, 1.0 + self.clip_ratio) * batch_advantages\n",
    "                \n",
    "                # Calculate loss components\n",
    "                policy_loss = -torch.min(surr1, surr2).mean()\n",
    "                value_loss = nn.MSELoss()(values.squeeze(-1), batch_returns)\n",
    "                entropy_loss = -entropy.mean()\n",
    "                \n",
    "                # Calculate total loss\n",
    "                loss = policy_loss + self.value_coef * value_loss + self.entropy_coef * entropy_loss\n",
    "                \n",
    "                # Perform optimization step\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.policy.parameters(), 0.5)  # Clip gradients\n",
    "                self.optimizer.step()\n",
    "        # Update old policy\n",
    "        self.old_policy.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        return policy_loss.item(), value_loss.item(), entropy_loss.item()\n",
    "    \n",
    "    def get_action(self, state, deterministic=False):\n",
    "        return self.policy.get_action(state, deterministic)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.policy.state_dict(), path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.policy.load_state_dict(torch.load(path))\n",
    "        self.old_policy.load_state_dict(torch.load(path))\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_ppo(env, agent, max_episodes=1000, steps_per_episode=128, \n",
    "              update_interval=10, eval_interval=50, verbose=True):\n",
    "    \n",
    "    # Initialize logging variables\n",
    "    episode_rewards = []\n",
    "    eval_rewards = []\n",
    "    best_intensity = 0\n",
    "    best_mask = None\n",
    "    \n",
    "    # Training loop\n",
    "    for episode in tqdm(range(1, max_episodes + 1)):\n",
    "        # Storage for the current episode\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "        dones = []\n",
    "        \n",
    "        episode_reward = 0\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Generate trajectory\n",
    "        for step in range(steps_per_episode):\n",
    "            # Select action\n",
    "            action = agent.get_action(state)\n",
    "            \n",
    "            # Execute action\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # Store transition\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            dones.append(done)\n",
    "            \n",
    "            # Update state and reward\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            \n",
    "        # Store episode reward\n",
    "        episode_rewards.append(episode_reward)\n",
    "        \n",
    "        # Update agent\n",
    "        if episode % update_interval == 0:\n",
    "            policy_loss, value_loss, entropy_loss = agent.update(\n",
    "                states, actions, rewards, next_states, dones\n",
    "            )\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Episode {episode}, Reward: {episode_reward:.4f}\")\n",
    "                print(f\"Policy Loss: {policy_loss:.4f}, Value Loss: {value_loss:.4f}, Entropy Loss: {entropy_loss:.4f}\")\n",
    "                print(f\"Current Intensity: {env.I_prev:.4f}, Max Intensity: {env.I_max:.4f}\")\n",
    "                print(\"---\")\n",
    "        \n",
    "        # Track best solution found\n",
    "        if env.I_max > best_intensity:\n",
    "            best_intensity = env.I_max\n",
    "            best_mask = env.block_mask.copy()\n",
    "        \n",
    "        # Evaluate performance\n",
    "        if episode % eval_interval == 0:\n",
    "            eval_reward = evaluate_agent(env, agent, num_episodes=5)\n",
    "            eval_rewards.append(eval_reward)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Evaluation at episode {episode}: Average Reward = {eval_reward:.4f}\")\n",
    "                print(\"===================================\")\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'eval_rewards': eval_rewards,\n",
    "        'best_intensity': best_intensity,\n",
    "        'best_mask': best_mask\n",
    "    }\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_agent(env, agent, num_episodes=5, steps_per_episode=128):\n",
    "    total_rewards = 0\n",
    "    \n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        \n",
    "        for _ in range(steps_per_episode):\n",
    "            action = agent.get_action(state, deterministic=True)  # Use deterministic policy for evaluation\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        total_rewards += episode_reward\n",
    "        \n",
    "    return total_rewards / num_episodes\n",
    "\n",
    "# Visualization functions\n",
    "def plot_training_curve(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot episode rewards\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(results['episode_rewards'], label='Episode Reward')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Training Rewards')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot evaluation rewards if available\n",
    "    if len(results['eval_rewards']) > 0:\n",
    "        plt.subplot(2, 1, 2)\n",
    "        eval_x = np.linspace(0, len(results['episode_rewards']), len(results['eval_rewards']))\n",
    "        plt.plot(eval_x, results['eval_rewards'], label='Evaluation Reward', color='orange')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Average Reward')\n",
    "        plt.title('Evaluation Rewards')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_best_mask(env, best_mask):\n",
    "    # Store original mask\n",
    "    original_mask = env.block_mask.copy()\n",
    "    \n",
    "    # Set the best mask\n",
    "    env.block_mask = best_mask.copy()\n",
    "    \n",
    "    # Get pixel mask\n",
    "    pixel_mask = env._blocks_to_pixels()\n",
    "    \n",
    "    # Get intensity\n",
    "    intensity = env._intensity()\n",
    "    \n",
    "    # Plot mask\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(pixel_mask, cmap='viridis')\n",
    "    plt.colorbar(label='Mask Value')\n",
    "    plt.title(f'Best Mask (Intensity: {intensity:.4f})')\n",
    "    plt.savefig('best_mask.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Restore original mask\n",
    "    env.block_mask = original_mask\n",
    "\n",
    "def main():\n",
    "    # Create environment\n",
    "    env = WavefrontEnv(slm_dim1=64, slm_dim2=64, num_pix_per_block=32, alpha=0.3, noise_sigma=0.05)\n",
    "    \n",
    "    # Create PPO agent\n",
    "    agent = PPOAgent(\n",
    "        state_dim=env.state_dim,\n",
    "        action_dim=env.action_space,\n",
    "        lr=3e-4,\n",
    "        gamma=0.99,\n",
    "        clip_ratio=0.2,\n",
    "        value_coef=0.5,\n",
    "        entropy_coef=0.01,\n",
    "        gae_lambda=0.95\n",
    "    )\n",
    "    \n",
    "    # Train agent\n",
    "    print(\"Starting training...\")\n",
    "    results = train_ppo(\n",
    "        env=env,\n",
    "        agent=agent,\n",
    "        max_episodes=500,  # Adjust based on your time constraints\n",
    "        steps_per_episode=128,\n",
    "        update_interval=5,\n",
    "        eval_interval=25\n",
    "    )\n",
    "    \n",
    "    # Save the trained model\n",
    "    agent.save('wavefront_ppo_model.pth')\n",
    "    \n",
    "    # Visualize results\n",
    "    plot_training_curve(results)\n",
    "    visualize_best_mask(env, results['best_mask'])\n",
    "    \n",
    "    print(f\"Training completed. Best intensity achieved: {results['best_intensity']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "def test_class_wavefront():\n",
    "    env = WavefrontEnv()\n",
    "    state = env.reset()\n",
    "    # print(\"Initial state:\", state)\n",
    "    print(\"output intensity\", env.I0_mean)\n",
    "\n",
    "    # Example: flip block 0\n",
    "    print(\"\\nFlipping block 0...\")\n",
    "    env.block_mask[0] = 1.0 - env.block_mask[0]  # toggle block 0\n",
    "    new_intensity = env._intensity()\n",
    "    print(\"New intensity after flipping block 0:\", new_intensity)\n",
    "\n",
    "    # Example: flip block 1\n",
    "    print(\"\\nFlipping block 1...\")\n",
    "    env.block_mask[1] = 1.0 - env.block_mask[1]\n",
    "    new_intensity = env._intensity()\n",
    "    print(\"New intensity after flipping block 1:\", new_intensity)\n",
    "\n",
    "    # Flip multiple blocks\n",
    "    print(\"\\nFlipping blocks 2, 3, and 4...\")\n",
    "    for b in [2, 3, 4]:\n",
    "        env.block_mask[b] = 1.0 - env.block_mask[b]\n",
    "    new_intensity = env._intensity()\n",
    "    print(\"Intensity after flipping blocks 2, 3, 4:\", new_intensity)\n",
    "\n",
    "def test_blocks_to_pixels():\n",
    "    env = WavefrontEnv()\n",
    "    env.reset()\n",
    "\n",
    "    print(f\"Total pixels: {env.n_pix}\")\n",
    "    print(f\"Number of blocks: {env.num_blocks}\")\n",
    "    print(f\"Pixels per block: {env.n_pix // env.num_blocks}\")\n",
    "\n",
    "    # Test 1: all blocks ON\n",
    "    env.block_mask[:] = 1.0\n",
    "    pixels = env._blocks_to_pixels()\n",
    "    print(\"All ON  Sum of pixels:\", pixels.sum())  # should be 4096\n",
    "\n",
    "    # Test 2: all blocks OFF\n",
    "    env.block_mask[:] = 0.0\n",
    "    pixels = env._blocks_to_pixels()\n",
    "    print(\"All OFF  Sum of pixels:\", pixels.sum())  # should be 0\n",
    "\n",
    "    # Test 3: only block 0 ON\n",
    "    env.block_mask[:] = 0.0\n",
    "    env.block_mask[5] = 1.0\n",
    "    pixels = env._blocks_to_pixels()\n",
    "    print(\"Only block 0 ON  Sum of pixels:\", pixels.sum())  # should be 32\n",
    "\n",
    "    # Show block 0 in image\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.title(\"Only Block 0 ON\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "test_blocks_to_pixels()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
